{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Scholar Scraping for Summarisation Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>url:</b> http://s2-public-api-prod.us-west-2.elasticbeanstalk.com/corpus/download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gzip\n",
    "import json\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifestFile = open(\"../data/sample/semantic scholar manifest 2020-03.txt\", \"r\")\n",
    "manifestFile = manifestFile.read()\n",
    "manifestFileList = manifestFile.split('\\n')\n",
    "manifestFileList = [file for file in manifestFileList if 's2' in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2CorpusUrl = '../data/s2-corpus-000.gz'    #'s2-corpus/sample-S2-records.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipS2Contents(url):\n",
    "    f = gzip.open(url, 'rb')\n",
    "    file_content = f.read().decode('utf-8')\n",
    "    f.close()\n",
    "    fileContentsList = file_content.split('\\n')\n",
    "    return fileContentsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fileContentsList = unzipS2Contents(s2CorpusUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999674"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fileContentsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"entities\":[],\"journalVolume\":\"\",\"journalPages\":\"\",\"pmid\":\"\",\"fieldsOfStudy\":[\"Physics\"],\"year\":2015,\"outCitations\":[\"2497ed63572e8d5e5fe7945f0b23e0d090acd51c\",\"03b317054274da28acfb2c8e082f38d7dcfdce04\",\"070c58ff3d4f5ca3383c20a23af3594ae6e564ab\",\"f9a1951720cafa3706b341c0d14ddd57d9c83043\",\"26052227014c270c3f6013d98fdb8db1b80f8607\",\"8de63b8021633e45585874468ff5fe4bfe3ee476\",\"91d9b8d56ce67a90abfe0c9fc7483b8220ad3c66\",\"5baead167bceac9bdcbd7ac808620bb8987da323\",\"778f2e33cb7b0dfc0d3925df852fa4e576e75890\",\"88a11402d59f026ae5cd93f044e0c038f4373d51\",\"c2038b5d11a4dd9017d7a410b93f088f4dc8d1e4\",\"fa1aff91383e227fc115fc0621fd7452ebca46ab\"],\"s2Url\":\"https://semanticscholar.org/paper/1b2f4e5be76a0a746b72110b447b42fffa046b5c\",\"s2PdfUrl\":\"\",\"id\":\"1b2f4e5be76a0a746b72110b447b42fffa046b5c\",\"authors\":[{\"name\":\"Xiang Fa Liu\",\"ids\":[\"153201706\"]},{\"name\":\"Guodong Xia\",\"ids\":[\"46932503\"]},{\"name\":\"Guo-zhen Yang\",\"ids\":[\"50147063\"]}],\"journalName\":\"\",\"paperAbstract\":\"Abstract Experimental investigations on the characteristics of air–water two-phase flow in the vertical helical rectangular channel are performed using the high speed flow visualization. The flow pattern map and the transition in the helical rectangular channel are presented. The flow pattern evolution in different positions of the helical rectangular channel is illustrated. The discussion on the coalescence of the bubble and slug is presented. The slug velocity, slug length distribution, liquid slug frequency, falling liquid film velocity and falling film thickness along the slug are investigated. The dimensionless liquid film thickness of the annular flow on the outer side of the channel is measured using the digital image processing algorithm.\",\"inCitations\":[],\"pdfUrls\":[\"http://www.mechwork.ir/uploads/papers/4-Experimental%20study%20on%20the%20characteristics%20of%20air-water%20two-phase%20flow%20in%20vertical.pdf\"],\"title\":\"Experimental study on the characteristics of air–water two-phase flow in vertical helical rectangular channel\",\"doi\":\"10.1016/j.ijmultiphaseflow.2015.03.012\",\"sources\":[],\"doiUrl\":\"https://doi.org/10.1016/j.ijmultiphaseflow.2015.03.012\",\"venue\":\"\"}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileContentsList[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyTermsList = ['summarisation', 'summarization', 'nlg', 'extractive', 'summeries']    # spelling problems...; removed automatic as it's too general when it matches by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File No.: 1962 - ERROR: No features in text.\n",
      "File No.: 3408 - ERROR: No features in text.\n",
      "File No.: 3591 - ERROR: No features in text.\n",
      "File No.: 7111 - ERROR: No features in text.\n",
      "File No.: 9483 - ERROR: No features in text.\n",
      "File No.: 10000 - Year: 1989 - Title: Epidemiological approaches for identifying risk factors in human congenital malformations : Abstracts of Papers Presented at the 29th Annual Meeting of the Japanese Teratology Society, Yamagata, Japan July 13 - 14\n",
      "File No.: 10129 - ERROR: No features in text.\n",
      "File No.: 13320 - ERROR: No features in text.\n",
      "File No.: 16084 - ERROR: No features in text.\n",
      "File No.: 17267 - ERROR: No features in text.\n",
      "File No.: 17351 - ERROR: No features in text.\n",
      "File No.: 19752 - ERROR: No features in text.\n",
      "File No.: 20000 - Year: 2009 - Title: Indian Adaptations in Flooded Regions of South America: Introduction\n",
      "File No.: 22540 - ERROR: No features in text.\n",
      "File No.: 24989 - ERROR: No features in text.\n",
      "File No.: 25199 - ERROR: No features in text.\n",
      "File No.: 25336 - ERROR: No features in text.\n",
      "File No.: 25600 - ERROR: No features in text.\n",
      "File No.: 25804 - ERROR: No features in text.\n",
      "File No.: 26630 - ERROR: No features in text.\n",
      "File No.: 27097 - ERROR: No features in text.\n",
      "File No.: 27751 - ERROR: No features in text.\n",
      "File No.: 29421 - ERROR: No features in text.\n",
      "File No.: 30000 - Year: 1956 - Title: Experimental Studies on the Habitat Preference and Evaluation of Environment by Flatfishes, Limanda yokohamae (GÜNTHER) and Kareius bicoloratus (BASILEWSKY)\n",
      "File No.: 31823 - ERROR: No features in text.\n",
      "File No.: 32502 - ERROR: No features in text.\n",
      "File No.: 32648 - ERROR: No features in text.\n",
      "File No.: 34138 - ERROR: No features in text.\n",
      "File No.: 35052 - ERROR: No features in text.\n",
      "File No.: 35206 - ERROR: No features in text.\n",
      "File No.: 36773 - ERROR: No features in text.\n",
      "File No.: 37797 - ERROR: No features in text.\n",
      "File No.: 37823 - ERROR: No features in text.\n",
      "File No.: 38049 - ERROR: No features in text.\n",
      "File No.: 38082 - ERROR: No features in text.\n",
      "File No.: 38637 - ERROR: No features in text.\n",
      "File No.: 38657 - ERROR: No features in text.\n",
      "File No.: 40000 - Year: 1993 - Title: Transient high-Rayleigh-number thermal convection with large viscosity variations\n",
      "File No.: 43693 - ERROR: No features in text.\n",
      "File No.: 47418 - ERROR: No features in text.\n",
      "File No.: 47428 - ERROR: No features in text.\n",
      "File No.: 47882 - ERROR: No features in text.\n",
      "File No.: 48200 - ERROR: No features in text.\n",
      "File No.: 48818 - ERROR: No features in text.\n",
      "File No.: 49111 - ERROR: No features in text.\n",
      "File No.: 49219 - ERROR: No features in text.\n",
      "File No.: 50000 - Year: 1951 - Title: Dust Control in the Asphalt Street Paving Industry.\n",
      "File No.: 50011 - ERROR: No features in text.\n",
      "File No.: 51006 - ERROR: No features in text.\n",
      "File No.: 51101 - ERROR: No features in text.\n",
      "File No.: 51380 - ERROR: No features in text.\n",
      "File No.: 51480 - ERROR: No features in text.\n",
      "File No.: 51605 - ERROR: No features in text.\n",
      "File No.: 53335 - ERROR: No features in text.\n",
      "File No.: 55112 - ERROR: No features in text.\n",
      "File No.: 55130 - ERROR: No features in text.\n",
      "File No.: 55279 - ERROR: No features in text.\n",
      "File No.: 59434 - ERROR: No features in text.\n",
      "File No.: 60000 - Year: 2012 - Title: The Impact of Health and Financial Literacy on Decision Making in Community-Based Older Adults\n",
      "File No.: 62284 - ERROR: No features in text.\n",
      "File No.: 65287 - ERROR: No features in text.\n",
      "File No.: 65900 - ERROR: No features in text.\n",
      "File No.: 70000 - Year: 2013 - Title: Full Factorial Design in Formulation of Lamotrigine Suspension using Locust Bean Gum\n",
      "File No.: 73401 - ERROR: No features in text.\n",
      "File No.: 73914 - ERROR: No features in text.\n",
      "File No.: 74813 - ERROR: No features in text.\n",
      "File No.: 75115 - ERROR: No features in text.\n",
      "File No.: 77535 - ERROR: No features in text.\n",
      "File No.: 77867 - ERROR: No features in text.\n",
      "File No.: 78212 - ERROR: No features in text.\n",
      "File No.: 78299 - ERROR: No features in text.\n",
      "File No.: 79934 - ERROR: No features in text.\n",
      "File No.: 80000 - Year: 2013 - Title: A New Maximum Likelihood Approach for Free Energy Profile Construction from Molecular Simulations.\n",
      "File No.: 83128 - ERROR: No features in text.\n",
      "File No.: 85876 - ERROR: No features in text.\n",
      "File No.: 86796 - ERROR: No features in text.\n",
      "File No.: 87451 - ERROR: No features in text.\n",
      "File No.: 88710 - ERROR: No features in text.\n",
      "File No.: 90000 - Year: 2018 - Title: Assessment of Influence of Miniature Sample Scoop on Creep Life of Piping\n",
      "File No.: 95286 - ERROR: No features in text.\n",
      "File No.: 96393 - ERROR: No features in text.\n",
      "File No.: 96450 - ERROR: No features in text.\n",
      "File No.: 99440 - ERROR: No features in text.\n",
      "File No.: 100000 - Year: 1998 - Title: The evolution of decision trees\n",
      "Wall time: 23min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Process documents and keep only the english ones.\n",
    "fileContentsListEnglish = []\n",
    "fileCount = 1\n",
    "noFilesToProcess = 100000\n",
    "\n",
    "for file in fileContentsList:\n",
    "    try:\n",
    "        fileJSON = json.loads(file)\n",
    "\n",
    "        if detect(fileJSON[\"title\"]) == 'en':\n",
    "            fileContentsListEnglish.append(file)\n",
    "            \n",
    "            if fileCount % (noFilesToProcess/10) == 0:\n",
    "                print(f'File No.: {fileCount} - Year: {fileJSON[\"year\"]} - Title: {fileJSON[\"title\"]}')\n",
    "\n",
    "            fileCount += 1   # only counting for english documents.\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'File No.: {fileCount} - ERROR: {e}')\n",
    "        \n",
    "    if fileCount == noFilesToProcess+1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Keep documents that contain key terms\n",
    "print(f'Number of english documents: {len(fileContentsListEnglish)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DOC MATCHED: An Effective Joint Framework for Document Summarization\n",
      "\n",
      "\n",
      "DOC MATCHED: Developments in Physical Chemistry and Basic Principles of Extractive Metallurgy in 1980\n",
      "\n",
      "\n",
      "DOC MATCHED: Political and economic implications of extractive industries\n",
      "\n",
      "\n",
      "DOC MATCHED: Belief as summarization and meta-support\n",
      "\n",
      "\n",
      "DOC MATCHED: Effect of Sea Cucumber Extractive on Erythrocyte Membrane Fluidity in Rats with Overtraining Syndrome\n",
      "\n",
      "\n",
      "DOC MATCHED: Automatic Generation of Summeries for the Web\n",
      "\n",
      "\n",
      "DOC MATCHED: A video summarization approach based on the emulation of bottom-up mechanisms of visual attention\n",
      "\n",
      "\n",
      "DOC MATCHED: Summarization Experiments in DUC 2004\n",
      "\n",
      "\n",
      "DOC MATCHED: QA@INEX Track 2011: Question Expansion and Reformulation Using the REG Summarization System\n",
      "\n",
      "\n",
      "DOC MATCHED: Summarization of news speech with unknown topic boundary\n",
      "\n",
      "\n",
      "DOC MATCHED: Attend to the beginning: A study on using bidirectional attention for extractive summarization\n",
      "\n",
      "\n",
      "DOC MATCHED: Topical Summarization on the Mayor and Schoolmaster Forum at 2009 Winter Universiade Sports Science Conference\n",
      "\n",
      "\n",
      "DOC MATCHED: Multicamera Summarization of Rehabilitation Sessions in Home Environment\n",
      "\n",
      "\n",
      "DOC MATCHED: A New Extractive Technology of the Silkworm Chrysalis Protein\n",
      "\n",
      "\n",
      "DOC MATCHED: Query-Focused Multi-Document Summarization Using Co-Training Based Semi-Supervised Learning\n",
      "\n",
      "\n",
      "DOC MATCHED: A simple synthesis of cyclotribromoveratrylene (CTBV) : an extractive of the red alga Halopytis pinastroides\n",
      "\n",
      "\n",
      "DOC MATCHED: Summarization of the Literatures on Human Resource Management of Chinese Library in the Last Few Years\n",
      "\n",
      "\n",
      "DOC MATCHED: GC analysis of extractive compounds in beech wood\n",
      "\n",
      "\n",
      "DOC MATCHED: Extractive Separation of Aluminum(III), Gallium(III)and Indium(III)Using Bis(1, 1, 3, 3, tetramethylbutyl)phosphinic Acid and Its Sulfur Analogues\n",
      "\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for file in fileContentsListEnglish:\n",
    "    \n",
    "    fileJSON = json.loads(file)\n",
    "    \n",
    "    keyTermsMatched = set(fileJSON[\"title\"].lower().split(' ')).intersection(set(keyTermsList))\n",
    "    \n",
    "    if (0 < len(keyTermsMatched)) :\n",
    "        print(f'\\nDOC MATCHED: {fileJSON[\"title\"]}\\n')\n",
    "    else:\n",
    "#         print(fileJSON[\"title\"])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SciBERT: https://github.com/allenai/scibert\n",
    "- Notebook: https://github.com/huggingface/transformers/blob/master/notebooks/02-transformers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17299bf27fed49ae86d4e4a03a0795dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=313.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f121466e3744eae8a001831ae48f459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=227845.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aa6c3f934e488388930cea63c053ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442221694.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x22c25bcd860>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['complementary', 'dual', '-', 'contact', 'switch', 'using', 'soft', 'and', 'hard', 'contact', 'materials', 'for', 'achieving', 'low', 'contact', 'resistance', 'and', 'high', 'reliability', 'simultaneously']\n",
      "Tokens id: [8487, 4793, 579, 3585, 6216, 487, 1720, 137, 2723, 3585, 2518, 168, 9153, 629, 3585, 2661, 137, 597, 4817, 5364]\n",
      "Tokens PyTorch: tensor([[ 102, 8487, 4793,  579, 3585, 6216,  487, 1720,  137, 2723, 3585, 2518,\n",
      "          168, 9153,  629, 3585, 2661,  137,  597, 4817, 5364,  103]])\n",
      "Token wise output: torch.Size([1, 22, 768]), Pooled output: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# Tokens comes from a process that splits the input into sub-entities with interesting linguistic properties. \n",
    "tokens = tokenizer.tokenize(\"Complementary Dual-Contact Switch Using Soft and Hard Contact Materials for Achieving Low Contact Resistance and High Reliability Simultaneously\")\n",
    "print(\"Tokens: {}\".format(tokens))\n",
    "\n",
    "# This is not sufficient for the model, as it requires integers as input, \n",
    "# not a problem, let's convert tokens to ids.\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(\"Tokens id: {}\".format(tokens_ids))\n",
    "\n",
    "# Add the required special tokens\n",
    "tokens_ids = tokenizer.build_inputs_with_special_tokens(tokens_ids)\n",
    "\n",
    "# We need to convert to a Deep Learning framework specific format, let's use PyTorch for now.\n",
    "tokens_pt = torch.tensor([tokens_ids])\n",
    "print(\"Tokens PyTorch: {}\".format(tokens_pt))\n",
    "\n",
    "# Now we're ready to go through BERT with out input\n",
    "outputs, pooled = model(tokens_pt)\n",
    "print(\"Token wise output: {}, Pooled output: {}\".format(outputs.shape, pooled.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0416, -0.1480, -0.6753,  0.8675,  0.2088,  0.9992,  0.2641, -0.9997,\n",
       "          0.2043,  0.7729,  0.1298,  0.5405,  0.7846,  0.7665, -0.4069, -0.0907,\n",
       "         -0.5304, -0.4133,  0.7156, -0.9106, -0.1457,  0.5916, -0.5221,  0.6518,\n",
       "          0.1237,  0.4443, -0.9847, -0.1341, -0.2130,  0.4250,  0.4813, -0.9459,\n",
       "          0.4612, -0.3520, -0.3998,  0.0332,  0.9989,  0.2931,  0.7156,  0.0493,\n",
       "         -0.5442,  0.2990,  0.4944, -0.4461,  0.5150, -0.0930, -0.4712,  0.3879,\n",
       "         -0.6986,  0.9627,  0.0752, -0.3971, -0.1057,  0.5300,  0.9873,  0.0485,\n",
       "         -0.2699,  0.3184, -0.6361,  0.5775,  0.0217, -0.9774,  0.4412,  0.5084,\n",
       "          0.5062, -0.4235, -0.2550, -0.3205,  0.9495,  0.2289,  0.9662,  0.3846,\n",
       "          0.1071, -0.7250,  0.9554,  0.0102, -0.0994, -0.3838,  0.0567,  0.1527,\n",
       "          0.2297,  0.1733,  0.0352, -0.9719, -0.5161, -0.4337, -0.0113, -0.3069,\n",
       "          0.9672, -0.7773, -0.4541,  0.0539, -0.4561,  0.0442, -0.4799,  0.2286,\n",
       "         -0.5568,  0.1368,  0.1195, -0.3294, -0.4048,  0.0691,  0.3708, -0.4985,\n",
       "         -0.1649, -0.1779, -0.2930, -0.2385, -0.1039,  0.6802, -0.1813, -0.1369,\n",
       "          0.1154, -0.4539, -0.1119,  0.4267,  0.9731,  0.6332, -0.1034,  0.1278,\n",
       "          0.4949, -0.0541,  0.9639, -0.1091, -0.3294, -0.0333, -0.5464,  0.1524,\n",
       "          0.2081,  0.1540, -0.4209,  0.4644, -0.5918, -0.1756, -0.2734,  0.1098,\n",
       "          0.4962,  0.0218,  0.9393, -0.0689, -0.4263, -0.2945, -0.0545,  0.1557,\n",
       "          0.6116,  0.3358,  0.0559,  0.0791,  0.2383,  0.6414, -0.3048, -0.3593,\n",
       "         -0.3908,  0.9976, -0.2609, -0.0796, -0.7665,  0.7430,  0.3581,  0.6486,\n",
       "          0.2229,  0.0159, -0.0761, -0.2760,  0.4320, -0.1492,  0.0761, -0.5120,\n",
       "          0.8507, -0.8693, -0.3426,  0.8054,  0.1354, -0.2426,  0.2911,  0.2636,\n",
       "         -0.8582, -0.2514, -0.9203,  0.9146,  0.2083,  0.9875, -0.1996,  0.1986,\n",
       "          0.1782, -0.8586, -0.3747,  0.4494, -0.5461,  0.1719, -0.5187,  0.4078,\n",
       "          0.2770,  0.3966, -0.9991,  0.1090,  0.4785, -0.3988,  0.1358,  0.1707,\n",
       "          0.3714, -0.9065,  0.1071, -0.6101,  0.7541,  0.3829, -0.5660,  0.0591,\n",
       "         -0.9972,  0.8866,  0.9288, -0.5124, -0.2371,  0.4281,  0.9730,  0.2716,\n",
       "         -0.9241, -0.9968, -0.2195, -0.0925,  0.2699,  0.9655, -0.2254,  0.0411,\n",
       "         -0.6005,  0.6791, -0.5053,  0.0876, -0.4009,  0.3692,  0.0561, -0.9979,\n",
       "         -0.3014,  0.8834, -0.3533,  0.5205,  0.3580,  0.3005, -0.4169, -0.0627,\n",
       "         -0.0773,  0.7489, -0.3394, -0.3506, -0.4260,  0.8877, -0.2933,  0.4190,\n",
       "         -0.6957, -0.9856,  0.6167, -0.5216,  0.8746, -0.3918, -0.0944, -0.5738,\n",
       "          0.8391, -0.9006,  0.7963, -0.0710, -0.1667,  0.4650,  0.0601,  0.1599,\n",
       "         -0.7321,  0.0809, -0.9963,  0.2061, -0.3604, -0.1968, -0.2536, -0.9381,\n",
       "         -0.9645, -0.8747, -0.0432,  0.3281, -0.3339,  0.0628,  0.5285, -0.1166,\n",
       "          0.0701, -0.1787,  0.3410, -0.8978,  0.3191,  0.0069,  0.1266, -0.8641,\n",
       "         -0.3170,  0.1356,  0.9955,  0.8952, -0.3230, -0.4738, -0.5609,  0.4648,\n",
       "         -0.6369,  0.3045, -0.3889,  0.4300, -0.5297, -0.0819,  0.2577,  0.0193,\n",
       "         -0.6426,  0.3830, -0.0189, -0.4553,  0.2643, -0.9923, -0.9317,  0.3354,\n",
       "         -0.4975, -0.6192, -0.4418,  0.1734,  0.1010, -0.1951,  0.9748,  0.4037,\n",
       "         -0.2188, -0.0514,  0.2031,  0.2008,  0.9674,  0.0266,  0.1356,  0.5986,\n",
       "         -0.8045, -0.5842, -0.0462, -0.1507,  0.6958,  0.3096, -0.1518, -0.1764,\n",
       "          0.9968,  0.0196, -0.8750, -0.0466, -0.2000,  0.2783,  0.3600, -0.6096,\n",
       "          0.0511,  0.3521, -0.0552, -0.3122, -0.1607, -0.0810, -0.1337, -0.0114,\n",
       "         -0.9490, -0.3292,  0.3724,  0.1598,  0.2367, -0.6257, -0.2256, -0.1700,\n",
       "         -0.4452, -0.2172,  0.3130,  0.4637, -0.3666,  0.0640, -0.7274,  0.1295,\n",
       "          0.4774, -0.1131,  0.2206, -0.4457, -0.1330,  0.2155, -0.0475, -0.5675,\n",
       "         -0.5051,  0.3830, -0.3525,  0.2788,  0.6116,  0.0182, -0.2822, -0.2569,\n",
       "          0.8846, -0.0311, -0.0935, -0.4207,  0.9911,  0.9795, -0.0238,  0.2702,\n",
       "          0.2881,  0.7691,  0.1559,  0.2860,  0.1005,  0.9993, -0.0155, -0.3393,\n",
       "         -0.9828, -0.4423,  0.2163,  0.0851,  0.1063, -0.0420, -0.4246, -0.7914,\n",
       "         -0.1327,  0.1801,  0.2978,  0.7374,  0.7086, -0.4970,  0.9824,  0.0311,\n",
       "          0.1630, -0.3176, -0.2915,  0.1869,  0.4440, -0.3539, -0.1822,  0.4904,\n",
       "         -0.2101, -0.2411, -0.5285,  0.2968, -0.1934, -0.0348,  0.2126,  0.5274,\n",
       "          0.4042,  0.9998,  0.7292,  0.4610, -0.2071,  0.3394,  0.0724, -0.9370,\n",
       "         -0.0786, -0.2686,  0.8323,  0.7573,  0.1347, -0.0196, -0.5004,  0.5278,\n",
       "         -0.9884, -0.2972, -0.0294, -0.0868,  0.0812,  0.8191,  0.0431, -0.2133,\n",
       "          0.0689, -0.9869, -0.1808, -0.0932, -0.0273,  0.1816,  0.1356,  0.3842,\n",
       "         -0.0688, -0.9765,  0.2089, -0.3097,  0.2525,  0.4863,  0.6546, -0.1553,\n",
       "         -0.7710,  0.3323,  0.9792, -0.1517,  0.9326, -0.0211,  0.1447,  0.4854,\n",
       "         -0.3628, -0.3833,  0.2484, -0.0798, -0.0505, -0.0738, -0.4105,  0.7318,\n",
       "          0.9512,  0.1359, -0.9436, -0.0969, -0.1003, -0.4599, -0.8771,  0.2154,\n",
       "         -0.6469,  0.0592,  0.1454, -0.0163, -0.8268, -0.9899,  0.9329, -0.1708,\n",
       "         -0.1286,  0.9124, -0.9397, -0.3924,  0.9888, -0.2074, -0.9904, -0.0297,\n",
       "          0.8994,  0.1558,  0.4494, -0.2894,  0.5539,  0.6273,  0.3194, -0.1893,\n",
       "         -0.4147, -0.2166,  0.9258,  0.4170, -0.6776, -0.2464, -0.0055,  0.9999,\n",
       "         -0.2654, -0.3309, -0.9810,  0.0260, -0.3424,  0.0073, -0.3945,  0.1532,\n",
       "          0.2895,  0.6775, -0.9672, -0.2593,  0.1869,  0.6343,  0.6534, -0.3145,\n",
       "         -0.2290, -0.1393, -0.9805,  0.9580, -0.2783,  0.3640, -0.0355,  0.4156,\n",
       "         -0.1774, -0.1837, -0.0204, -0.3430, -0.1076,  0.2755, -0.0395,  0.9167,\n",
       "         -0.4678,  0.2974,  0.5708,  0.5639,  0.9986,  0.4741, -0.8286,  0.5910,\n",
       "         -0.2182,  0.2572, -0.4677, -0.9776,  0.2944, -0.6679,  0.3096, -0.4069,\n",
       "          0.2608,  0.2998,  0.5558, -0.0472,  0.8396,  0.9798,  0.9995, -0.4936,\n",
       "          0.3826,  0.7620, -0.1416, -0.4683, -0.0602,  0.4190, -0.0839,  0.9435,\n",
       "         -0.9428, -0.0319, -0.2981,  0.1914,  0.1877,  0.5223, -0.4512, -0.1258,\n",
       "         -0.5326, -0.2117,  0.1205, -0.3300, -0.1290, -0.3234, -0.3544, -0.5649,\n",
       "         -0.1233,  0.4755, -0.6007,  0.0240, -0.0630, -0.3357,  0.3149,  0.6157,\n",
       "         -0.3328, -0.1442,  0.9103, -0.3121,  0.4517, -0.6567, -0.2178, -0.3307,\n",
       "         -0.0034, -0.4409,  0.9827, -0.9391, -0.1273,  0.7315, -0.9991, -0.2666,\n",
       "         -0.2201,  0.3616,  0.1316, -0.9357,  0.2206,  0.3860,  0.5741, -0.9991,\n",
       "          0.1652, -0.9980,  0.1087, -0.1881,  0.3682, -0.8243,  0.6546, -0.0184,\n",
       "         -0.6050,  0.3051, -0.1442,  0.9799,  0.9653, -0.3740, -0.3297, -0.3587,\n",
       "          0.1937,  0.2217,  0.1809, -0.9697,  0.6534,  0.0885,  0.3281,  0.9064,\n",
       "          0.0303,  0.4839, -0.4969,  0.9936, -0.3229, -0.1772, -0.4400,  0.8804,\n",
       "         -0.3160, -0.9825,  0.1065,  0.8626, -0.4526, -0.3301, -0.0557,  0.1420,\n",
       "         -0.3287, -0.9412,  0.3308, -0.3623,  0.1986, -0.3249, -0.5099,  0.3101,\n",
       "          0.5927, -0.9988,  0.1233,  0.2249, -0.1587, -0.5490, -0.8263,  0.3676,\n",
       "         -0.7677, -0.0291, -0.4707, -0.4070,  0.2284,  0.9478,  0.9202,  0.8387,\n",
       "         -0.2694,  0.2556,  0.2134, -0.9097, -0.0358,  0.3654, -0.1768,  0.0137,\n",
       "          0.7435, -0.2173, -0.3221,  0.2255, -0.9699, -0.1819, -0.9804, -0.9970,\n",
       "         -0.5734, -0.0562,  0.9826,  0.2913, -0.7532, -0.9443,  0.2709,  0.3524,\n",
       "         -0.1730,  0.6314, -0.3907,  0.1856,  0.6969,  0.1058,  0.6652,  0.8568,\n",
       "          0.1754, -0.4269,  0.0398, -0.9647,  0.3142,  0.9996, -0.1214,  0.6381,\n",
       "          0.2295,  0.9962, -0.2931,  0.4087, -0.1740,  0.7735, -0.9590,  0.9832,\n",
       "          0.3183, -0.2457,  0.1696,  0.1607, -0.2755,  0.5843, -0.4236, -0.2376,\n",
       "         -0.9963,  0.0428,  0.0577, -0.0914,  0.1700, -0.2190,  0.6924, -0.1045]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "\ttensor([[ 102, 8487, 4793,  579, 3585, 6216,  487, 1720,  137, 2723, 3585, 2518,\n",
      "          168, 9153,  629, 3585, 2661,  137,  597, 4817, 5364,  103]])\n",
      "token_type_ids:\n",
      "\ttensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "attention_mask:\n",
      "\ttensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Difference with previous code: (0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# tokens = tokenizer.tokenize(\"This is an input example\")\n",
    "# tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# tokens_pt = torch.tensor([tokens_ids])\n",
    "\n",
    "# This code can be factored into one-line as follow\n",
    "tokens_pt2 = tokenizer.encode_plus(\"Complementary Dual-Contact Switch Using Soft and Hard Contact Materials for Achieving Low Contact Resistance and High Reliability Simultaneously\", return_tensors=\"pt\")\n",
    "\n",
    "for key, value in tokens_pt2.items():\n",
    "    print(\"{}:\\n\\t{}\".format(key, value))\n",
    "\n",
    "outputs2, pooled2 = model(**tokens_pt2)\n",
    "print(\"Difference with previous code: ({}, {})\".format((outputs2 - outputs).sum(), (pooled2 - pooled).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
